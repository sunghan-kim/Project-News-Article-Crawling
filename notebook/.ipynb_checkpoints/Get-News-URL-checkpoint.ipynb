{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 뉴스 URL 얻기\n",
    "\n",
    "- rawdata에 있는 기사들의 URL 주소를 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.1 rawdata 디렉토리 탐색\n",
    "\n",
    "- `rawdata` 경로 안에 있는 모든 `.md` 파일 안에 포함된 기사 링크를 얻기 위해 먼저 확장자로 `.md`를 갖는 파일의 경로 및 파일명을 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['..\\\\rawdata\\\\기업별 관련기사\\\\IT\\\\네이버\\\\20200416 네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분.md',\n",
       " '..\\\\rawdata\\\\기업별 관련기사\\\\IT\\\\우리에프아이에스\\\\20200421 창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융.md',\n",
       " '..\\\\rawdata\\\\기업별 관련기사\\\\IT\\\\카카오\\\\20200416 네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분.md',\n",
       " \"..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200204 보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까.md\",\n",
       " \"..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200206 '디지털' 속도 내는 보험업계…디지털보험사 줄잇는다.md\",\n",
       " '..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200206 ‘역대 호황’ 누린 은행들의 고민…“올해는 힘들다”.md',\n",
       " '..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200206 “길 잃은 돈 잡아라”… 은행·핀테크 ‘소액 자산관리 전쟁’.md',\n",
       " '..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200206 김정태의 승부수…금융지주 초대형IB경쟁 본격화.md',\n",
       " \"..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200219 '신탁상품' 못키운 한국…노인들 'DLF'로 몰았다.md\",\n",
       " \"..\\\\rawdata\\\\기업별 관련기사\\\\_공통\\\\20200219 '지수 ETF'로 피신하는 외국인·기관.md\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "ROOT_PATH = \"..\\\\rawdata\\\\기업별 관련기사\"\n",
    "file_list = []\n",
    "\n",
    "for (path, dir, files) in os.walk(ROOT_PATH):\n",
    "    \n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1]\n",
    "        \n",
    "        if ext == \".md\":\n",
    "            file_list.append(os.path.join(path, file))\n",
    "            \n",
    "file_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.2 파일명 추출\n",
    "\n",
    "- 기사 작성일자와 기사 제목이 포함된 파일명을 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200416 네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분.md',\n",
       " '20200421 창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융.md',\n",
       " '20200416 네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분.md',\n",
       " \"20200204 보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까.md\",\n",
       " \"20200206 '디지털' 속도 내는 보험업계…디지털보험사 줄잇는다.md\",\n",
       " '20200206 ‘역대 호황’ 누린 은행들의 고민…“올해는 힘들다”.md',\n",
       " '20200206 “길 잃은 돈 잡아라”… 은행·핀테크 ‘소액 자산관리 전쟁’.md',\n",
       " '20200206 김정태의 승부수…금융지주 초대형IB경쟁 본격화.md',\n",
       " \"20200219 '신탁상품' 못키운 한국…노인들 'DLF'로 몰았다.md\",\n",
       " \"20200219 '지수 ETF'로 피신하는 외국인·기관.md\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename_list = [file.split(\"\\\\\")[-1] for file in file_list]\n",
    "filename_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.3 기사 작성일자 및 제목 분리\n",
    "\n",
    "- 파일명에서 기사 작성일자와 기사제목을 분리한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20200416',\n",
       " '20200421',\n",
       " '20200416',\n",
       " '20200204',\n",
       " '20200206',\n",
       " '20200206',\n",
       " '20200206',\n",
       " '20200206',\n",
       " '20200219',\n",
       " '20200219']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 작성 일자\n",
    "news_date = [filename[:8] for filename in filename_list]\n",
    "news_date[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분',\n",
       " '창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융',\n",
       " '네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분',\n",
       " \"보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까\",\n",
       " \"'디지털' 속도 내는 보험업계…디지털보험사 줄잇는다\",\n",
       " '‘역대 호황’ 누린 은행들의 고민…“올해는 힘들다”',\n",
       " '“길 잃은 돈 잡아라”… 은행·핀테크 ‘소액 자산관리 전쟁’',\n",
       " '김정태의 승부수…금융지주 초대형IB경쟁 본격화',\n",
       " \"'신탁상품' 못키운 한국…노인들 'DLF'로 몰았다\",\n",
       " \"'지수 ETF'로 피신하는 외국인·기관\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# 기사 제목\n",
    "news_title = [os.path.splitext(filename[9:])[0] for filename in filename_list]\n",
    "news_title[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.4 데이터프레임 생성\n",
    "\n",
    "- 뉴스 작성일자, 뉴스 제목, 파일 경로를 포함하는 데이터프레임 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDate</th>\n",
       "      <th>NewsTitle</th>\n",
       "      <th>Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200416</td>\n",
       "      <td>네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\네이버\\20200416 네이버 먹거리, 우...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200421</td>\n",
       "      <td>창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\우리에프아이에스\\20200421 창업부터 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200416</td>\n",
       "      <td>네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\카카오\\20200416 네이버 먹거리, 우...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200204</td>\n",
       "      <td>보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\_공통\\20200204 보험업계는 '제로성장'이...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200206</td>\n",
       "      <td>'디지털' 속도 내는 보험업계…디지털보험사 줄잇는다</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\_공통\\20200206 '디지털' 속도 내는 보...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDate                           NewsTitle  \\\n",
       "0  20200416    네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분   \n",
       "1  20200421     창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융   \n",
       "2  20200416    네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분   \n",
       "3  20200204  보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까   \n",
       "4  20200206        '디지털' 속도 내는 보험업계…디지털보험사 줄잇는다   \n",
       "\n",
       "                                                Path  \n",
       "0  ..\\rawdata\\기업별 관련기사\\IT\\네이버\\20200416 네이버 먹거리, 우...  \n",
       "1  ..\\rawdata\\기업별 관련기사\\IT\\우리에프아이에스\\20200421 창업부터 ...  \n",
       "2  ..\\rawdata\\기업별 관련기사\\IT\\카카오\\20200416 네이버 먹거리, 우...  \n",
       "3  ..\\rawdata\\기업별 관련기사\\_공통\\20200204 보험업계는 '제로성장'이...  \n",
       "4  ..\\rawdata\\기업별 관련기사\\_공통\\20200206 '디지털' 속도 내는 보...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({\"NewsDate\": news_date, \"NewsTitle\": news_title, \"Path\": file_list})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.5 (테스트) 뉴스 기사 `md` 파일 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 20200416 네이버 \"먹거리, 우리가 키운다\" vs 카카오 \"같이 키우실 분~\"\n",
      "\n",
      "[기사링크](<https://www.hankyung.com/it/article/202004151310i>)\n",
      "\n",
      "\n",
      "\n",
      "> **양대 포털, 엇갈린 '미래 먹거리 전략'** \n",
      ">\n",
      "> \n",
      ">\n",
      "> **네이버, 현금 4兆 보유로 '넉넉'**\n",
      "> **알짜 자회사에 수천억 쏟아부어**\n",
      ">\n",
      "> \n",
      ">\n",
      "> **카카오, 벤처캐피털 등서 자금조달** \n",
      "> **카카오M 2100억 투자 받기도**  \n",
      "\n",
      "\n",
      "\n",
      "인터넷업계 양대 맞수인 네이버와 카카오가 각기 다른 투자 방식으로 미래\n"
     ]
    }
   ],
   "source": [
    "path = df['Path'][0]\n",
    "data = \"\"\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "    print(data[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.6 (테스트) 정규 표현식 이용 URL 주소 획득"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.hankyung.com/it/article/202004151310i'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "data = \"\"\n",
    "path = df['Path'][0]\n",
    "\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    data = f.read()\n",
    "\n",
    "#urlRgx = \"(http|https):\\/\\/(([\\xA1-\\xFEa-z0-9_\\-]+\\.[\\xA1-\\xFEa-z0-9:;&#@=_~%\\?\\/\\.\\,\\+\\-]+))\"\n",
    "urlRgx = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "urls = re.findall(urlRgx, data)\n",
    "[x[0] for x in urls][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.8 (테스트) 파일에 있는 기사 링크 가져오기\n",
    "\n",
    "- 기사 링크는 파일 내용 중 `[기사링크](<https://www.hankyung.com/it/article/202004151310i>)` 형태로 들어 있다.\n",
    "- 파일의 상단 제목 아래에 위치해 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 수정 필요 경로 확인\n",
    "\n",
    "import re\n",
    "\n",
    "urlRgx = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "\n",
    "mod_list = []\n",
    "\n",
    "for path in df['Path']:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        data = f.read()\n",
    "        if \"기사링크\" not in data:\n",
    "            mod_list.append(path)\n",
    "            \n",
    "mod_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.8 모든 파일에 있는 기사 링크 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.hankyung.com/it/article/202004151310i',\n",
       " 'https://www.hankyung.com/economy/article/2020042027491',\n",
       " 'https://www.hankyung.com/it/article/202004151310i',\n",
       " 'https://n.news.naver.com/article/025/0002972080',\n",
       " 'http://news1.kr/articles/?3833484',\n",
       " 'http://www.donga.com/news/article/all/20200204/99535656/1',\n",
       " 'http://news.kmib.co.kr/article/view.asp?arcid=0924121031&code=11151300&cp=nv',\n",
       " 'http://news.heraldcorp.com/view.php?ud=20200205000286',\n",
       " 'https://www.mk.co.kr/news/economy/view/2020/02/168288/',\n",
       " 'https://www.hankyung.com/finance/article/202002183788i']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "urlRgx = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "url_list = []\n",
    "\n",
    "for path in df['Path']:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        \n",
    "        url = \"\"\n",
    "        \n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"기사링크\" in line:\n",
    "                urls = re.findall(urlRgx, line)\n",
    "                url = urls[0][0]\n",
    "                url_list.append(url)\n",
    "                break\n",
    "\n",
    "url_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.9 데이터프레임에 기사 링크 추가\n",
    "\n",
    "- 획득한 기사 링크를 데이터프레임에 `URL` 컬럼으로 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsDate</th>\n",
       "      <th>NewsTitle</th>\n",
       "      <th>Path</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20200416</td>\n",
       "      <td>네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\네이버\\20200416 네이버 먹거리, 우...</td>\n",
       "      <td>https://www.hankyung.com/it/article/202004151310i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20200421</td>\n",
       "      <td>창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\우리에프아이에스\\20200421 창업부터 ...</td>\n",
       "      <td>https://www.hankyung.com/economy/article/20200...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20200416</td>\n",
       "      <td>네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\IT\\카카오\\20200416 네이버 먹거리, 우...</td>\n",
       "      <td>https://www.hankyung.com/it/article/202004151310i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200204</td>\n",
       "      <td>보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\_공통\\20200204 보험업계는 '제로성장'이...</td>\n",
       "      <td>https://n.news.naver.com/article/025/0002972080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20200206</td>\n",
       "      <td>'디지털' 속도 내는 보험업계…디지털보험사 줄잇는다</td>\n",
       "      <td>..\\rawdata\\기업별 관련기사\\_공통\\20200206 '디지털' 속도 내는 보...</td>\n",
       "      <td>http://news1.kr/articles/?3833484</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NewsDate                           NewsTitle  \\\n",
       "0  20200416    네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분   \n",
       "1  20200421     창업부터 독립까지 밀어준다…사내벤처 3곳 키우는 우리금융   \n",
       "2  20200416    네이버 먹거리, 우리가 키운다 vs 카카오 같이 키우실 분   \n",
       "3  20200204  보험업계는 '제로성장'이라는데, 은행들은 왜 보험사를 사들일까   \n",
       "4  20200206        '디지털' 속도 내는 보험업계…디지털보험사 줄잇는다   \n",
       "\n",
       "                                                Path  \\\n",
       "0  ..\\rawdata\\기업별 관련기사\\IT\\네이버\\20200416 네이버 먹거리, 우...   \n",
       "1  ..\\rawdata\\기업별 관련기사\\IT\\우리에프아이에스\\20200421 창업부터 ...   \n",
       "2  ..\\rawdata\\기업별 관련기사\\IT\\카카오\\20200416 네이버 먹거리, 우...   \n",
       "3  ..\\rawdata\\기업별 관련기사\\_공통\\20200204 보험업계는 '제로성장'이...   \n",
       "4  ..\\rawdata\\기업별 관련기사\\_공통\\20200206 '디지털' 속도 내는 보...   \n",
       "\n",
       "                                                 URL  \n",
       "0  https://www.hankyung.com/it/article/202004151310i  \n",
       "1  https://www.hankyung.com/economy/article/20200...  \n",
       "2  https://www.hankyung.com/it/article/202004151310i  \n",
       "3    https://n.news.naver.com/article/025/0002972080  \n",
       "4                  http://news1.kr/articles/?3833484  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['URL'] = url_list\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.10 `csv` 파일 저장\n",
    "\n",
    "- 위와 같이 생성한 데이터프레임을 `csv` 파일로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜 기준으로 정렬 후 저장\n",
    "df.sort_values(by=['NewsDate'], axis=0, inplace=True)\n",
    "df.to_csv('news_info.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## 1.11 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ROOT_PATH = \"..\\\\rawdata\\\\기업별 관련기사\"\n",
    "\n",
    "# 기사 파일 경로\n",
    "file_list = []\n",
    "\n",
    "for (path, dir, files) in os.walk(ROOT_PATH):\n",
    "    for file in files:\n",
    "        ext = os.path.splitext(file)[-1]\n",
    "        if ext == \".md\":\n",
    "            file_list.append(os.path.join(path, file))\n",
    "            \n",
    "#file_list[:10]\n",
    "\n",
    "# 작성 일자와 기사 제목 정보가 포함된 파일명\n",
    "filename_list = [file.split(\"\\\\\")[-1] for file in file_list]\n",
    "#filename_list[:10]\n",
    "\n",
    "# 작성 일자\n",
    "news_date = [filename[:8] for filename in filename_list]\n",
    "#news_date[:10]\n",
    "\n",
    "# 기사 제목\n",
    "news_title = [os.path.splitext(filename[9:])[0] for filename in filename_list]\n",
    "#news_title[:10]\n",
    "\n",
    "\n",
    "# 데이터프레임 생성\n",
    "df = pd.DataFrame({\"NewsDate\": news_date, \"NewsTitle\": news_title, \"Path\": file_list})\n",
    "#df.head()\n",
    "\n",
    "# 기사 링크(URL)\n",
    "urlRgx = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n",
    "url_list = []\n",
    "\n",
    "for path in df['Path']:\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        url = \"\"\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            if \"기사링크\" in line:\n",
    "                urls = re.findall(urlRgx, line)\n",
    "                url = urls[0][0]\n",
    "                url_list.append(url)\n",
    "                break\n",
    "\n",
    "#url_list[:10]\n",
    "\n",
    "# 데이터프레임에 기사 링크 추가\n",
    "df['URL'] = url_list\n",
    "#df.head()\n",
    "\n",
    "# 날짜 기준으로 정렬\n",
    "df.sort_values(by=['NewsDate'], axis=0, inplace=True)\n",
    "\n",
    "# 데이터프레임 csv로 저장\n",
    "try:\n",
    "    df.to_csv('news_info.csv', index=False)\n",
    "    print(\"Saved\")\n",
    "except:\n",
    "    print(\"Save Error\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
